{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0.post4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import torch\n",
    "torch.manual_seed(1235)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "codebase = '../../'\n",
    "sys.path.append(codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'exp_132'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.visual_genome import VGDataLoader, VG\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from config import ModelConfig, BOX_SCALE, IM_SCALE\n",
    "from torch.nn import functional as F\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm\n",
    "from lib.evaluation.sg_eval import BasicSceneGraphEvaluator, calculate_mR_from_evaluator_list, eval_entry\n",
    "from lib.pytorch_misc import print_para\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from lib.my_model_33 import KERN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~ Hyperparameters used: ~~~~~~~\n",
      "ckpt : checkpoints/vgdet/vg-24.tar\n",
      "save_dir : checkpoints/kern_predcls/exp_132\n",
      "num_gpus : 1\n",
      "num_workers : 1\n",
      "lr : 0.0001\n",
      "batch_size : 4\n",
      "val_size : 5000\n",
      "l2 : 0.0001\n",
      "adamwd : 0.0\n",
      "clip : 5.0\n",
      "print_interval : 1000\n",
      "mode : predcls\n",
      "cache : \n",
      "adam : True\n",
      "test : False\n",
      "num_epochs : 50\n",
      "use_resnet : False\n",
      "use_proposals : False\n",
      "pooling_dim : 4096\n",
      "use_ggnn_obj : False\n",
      "ggnn_obj_time_step_num : 3\n",
      "ggnn_obj_hidden_dim : 512\n",
      "ggnn_obj_output_dim : 512\n",
      "use_obj_knowledge : False\n",
      "obj_knowledge : \n",
      "use_ggnn_rel : False\n",
      "ggnn_rel_time_step_num : 3\n",
      "ggnn_rel_hidden_dim : 512\n",
      "ggnn_rel_output_dim : 512\n",
      "use_rel_knowledge : False\n",
      "rel_knowledge : \n",
      "tb_log_dir : summaries/kern_predcls/exp_132\n",
      "save_rel_recall : \n"
     ]
    }
   ],
   "source": [
    "conf = ModelConfig(f'''\n",
    "-m predcls -p 1000 -clip 5 \n",
    "-tb_log_dir summaries/kern_predcls/{exp_name} \n",
    "-save_dir checkpoints/kern_predcls/{exp_name}\n",
    "-ckpt checkpoints/vgdet/vg-24.tar \n",
    "-val_size 5000 \n",
    "-adam \n",
    "-b 4\n",
    "-ngpu 1\n",
    "-lr 1e-4 \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _ = VG.splits(num_val_im=conf.val_size, filter_duplicate_rels=True,\n",
    "                          use_proposals=conf.use_proposals,\n",
    "                          filter_non_overlap=conf.mode == 'sgdet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_predicates = train.ind_to_predicates # ind_to_predicates[0] means no relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = VGDataLoader.splits(train, val, mode='rel',\n",
    "                                               batch_size=conf.batch_size,\n",
    "                                               num_workers=conf.num_workers,\n",
    "                                               num_gpus=conf.num_gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = KERN(classes=train.ind_to_classes, rel_classes=train.ind_to_predicates,\n",
    "                num_gpus=conf.num_gpus, mode=conf.mode, require_overlap_det=True,\n",
    "                use_resnet=conf.use_resnet, use_proposals=conf.use_proposals, pooling_dim=conf.pooling_dim,\n",
    "                ggnn_rel_time_step_num=3, ggnn_rel_hidden_dim=1024, ggnn_rel_output_dim=None,\n",
    "                graph_path=os.path.join(codebase, 'graphs/005/all_edges.pkl'), \n",
    "                emb_path=os.path.join(codebase, 'graphs/001/emb_mtx.pkl'), \n",
    "                rel_counts_path=os.path.join(codebase, 'graphs/001/pred_counts.pkl'), \n",
    "                use_knowledge=True, use_embedding=True, refine_obj_cls=False,\n",
    "                class_volume=1.0, top_k_to_keep=5, normalize_messages=False,\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the detector\n",
    "for n, param in detector.detector.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 444.6M total parameters \n",
      " ----- \n",
      " \n",
      "detector.roi_fmap.0.weight                        : [4096,25088]    (102760448) (    )\n",
      "roi_fmap.1.0.weight                               : [4096,25088]    (102760448) (grad)\n",
      "roi_fmap_obj.0.weight                             : [4096,25088]    (102760448) (grad)\n",
      "detector.roi_fmap.3.weight                        : [4096,4096]     (16777216) (    )\n",
      "roi_fmap.1.3.weight                               : [4096,4096]     (16777216) (grad)\n",
      "roi_fmap_obj.3.weight                             : [4096,4096]     (16777216) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: [3328,3328]     (11075584) (grad)\n",
      "ggnn_rel_reason.obj_proj.weight                   : [1024,4096]     ( 4194304) (grad)\n",
      "ggnn_rel_reason.rel_proj.weight                   : [1024,4096]     ( 4194304) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: [2048,2048]     ( 4194304) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: [1024,3328]     ( 3407872) (grad)\n",
      "detector.bbox_fc.weight                           : [604,4096]      ( 2473984) (    )\n",
      "detector.features.19.weight                       : [512,512,3,3]   ( 2359296) (    )\n",
      "detector.features.21.weight                       : [512,512,3,3]   ( 2359296) (    )\n",
      "detector.features.24.weight                       : [512,512,3,3]   ( 2359296) (    )\n",
      "detector.features.26.weight                       : [512,512,3,3]   ( 2359296) (    )\n",
      "detector.features.28.weight                       : [512,512,3,3]   ( 2359296) (    )\n",
      "detector.rpn_head.conv.0.weight                   : [512,512,3,3]   ( 2359296) (    )\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: [1024,2048]     ( 2097152) (grad)\n",
      "detector.features.17.weight                       : [512,256,3,3]   ( 1179648) (    )\n",
      "union_boxes.conv.4.weight                         : [512,256,3,3]   ( 1179648) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: [1024,1024]     ( 1048576) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: [1024,768]      (  786432) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: [1024,768]      (  786432) (grad)\n",
      "detector.score_fc.weight                          : [151,4096]      (  618496) (    )\n",
      "detector.features.12.weight                       : [256,256,3,3]   (  589824) (    )\n",
      "detector.features.14.weight                       : [256,256,3,3]   (  589824) (    )\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: [768,768]       (  589824) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: [768,768]       (  589824) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: [512,1024]      (  524288) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: [512,1024]      (  524288) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: [512,1024]      (  524288) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: [512,1024]      (  524288) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : [1024,300]      (  307200) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : [1024,300]      (  307200) (grad)\n",
      "detector.features.10.weight                       : [256,128,3,3]   (  294912) (    )\n",
      "detector.features.7.weight                        : [128,128,3,3]   (  147456) (    )\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: [256,512]       (  131072) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: [256,512]       (  131072) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: [256,512]       (  131072) (grad)\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: [256,512]       (  131072) (grad)\n",
      "detector.features.5.weight                        : [128,64,3,3]    (   73728) (    )\n",
      "detector.rpn_head.conv.2.weight                   : [120,512,1,1]   (   61440) (    )\n",
      "detector.features.2.weight                        : [64,64,3,3]     (   36864) (    )\n",
      "union_boxes.conv.0.weight                         : [256,2,7,7]     (   25088) (grad)\n",
      "detector.features.0.weight                        : [64,3,3,3]      (    1728) (    )\n",
      "union_boxes.conv.6.weight                         : [512]           (     512) (grad)\n",
      "union_boxes.conv.2.weight                         : [256]           (     256) (grad)\n"
     ]
    }
   ],
   "source": [
    "print(print_para(detector), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(lr):\n",
    "    # Lower the learning rate on the VGG fully connected layers by 1/10th. It's a hack, but it helps\n",
    "    # stabilize the models.\n",
    "    fc_params = [p for n,p in detector.named_parameters() if n.startswith('roi_fmap') and p.requires_grad]\n",
    "    non_fc_params = [p for n,p in detector.named_parameters() if not n.startswith('roi_fmap') and p.requires_grad]\n",
    "    params = [{'params': fc_params, 'lr': lr / 10.0}, {'params': non_fc_params}]\n",
    "    # params = [p for n,p in detector.named_parameters() if p.requires_grad]\n",
    "\n",
    "    if conf.adam:\n",
    "        optimizer = optim.Adam(params, weight_decay=conf.adamwd, lr=lr, eps=1e-3)\n",
    "    else:\n",
    "        optimizer = optim.SGD(params, weight_decay=conf.l2, lr=lr, momentum=0.9)\n",
    "\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.1,\n",
    "    #                               verbose=True, threshold=0.0001, threshold_mode='abs', cooldown=1)\n",
    "    return optimizer #, scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(conf.ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.ckpt.split('-')[-2].split('/')[-1] == 'vgrel':\n",
    "    print(\"Loading EVERYTHING\")\n",
    "    start_epoch = ckpt['epoch']\n",
    "\n",
    "    if not optimistic_restore(detector, ckpt['state_dict']):\n",
    "        start_epoch = -1\n",
    "        # optimistic_restore(detector.detector, torch.load('checkpoints/vgdet/vg-28.tar')['state_dict'])\n",
    "else:\n",
    "    start_epoch = -1\n",
    "    optimistic_restore(detector.detector, ckpt['state_dict'])\n",
    "\n",
    "    detector.roi_fmap[1][0].weight.data.copy_(ckpt['state_dict']['roi_fmap.0.weight'])\n",
    "    detector.roi_fmap[1][3].weight.data.copy_(ckpt['state_dict']['roi_fmap.3.weight'])\n",
    "    detector.roi_fmap[1][0].bias.data.copy_(ckpt['state_dict']['roi_fmap.0.bias'])\n",
    "    detector.roi_fmap[1][3].bias.data.copy_(ckpt['state_dict']['roi_fmap.3.bias'])\n",
    "\n",
    "    detector.roi_fmap_obj[0].weight.data.copy_(ckpt['state_dict']['roi_fmap.0.weight'])\n",
    "    detector.roi_fmap_obj[3].weight.data.copy_(ckpt['state_dict']['roi_fmap.3.weight'])\n",
    "    detector.roi_fmap_obj[0].bias.data.copy_(ckpt['state_dict']['roi_fmap.0.bias'])\n",
    "    detector.roi_fmap_obj[3].bias.data.copy_(ckpt['state_dict']['roi_fmap.3.bias'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.cuda();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch_num):\n",
    "    detector.train()\n",
    "    tr = []\n",
    "    start = time.time()\n",
    "    for b, batch in enumerate(train_loader):\n",
    "        result, loss_pd = train_batch(batch, verbose=b % (conf.print_interval*10) == 0)\n",
    "        tr.append(loss_pd)\n",
    "        '''\n",
    "        if epoch_num == 1 and b % 1000 == 0:\n",
    "            print('\\n\\n\\n\\n-------------------------------------------------------------------\\n\\n\\n\\n')\n",
    "            print(detector.ggnn_rel_reason.ggnn.debug_info)        \n",
    "        '''\n",
    "        if b % conf.print_interval == 0 and b >= conf.print_interval:\n",
    "            mn = pd.concat(tr[-conf.print_interval:], axis=1).mean(1)\n",
    "            time_per_batch = (time.time() - start) / conf.print_interval\n",
    "            print(\"\\ne{:2d}b{:5d}/{:5d} {:.3f}s/batch, {:.1f}m/epoch\".format(\n",
    "                epoch_num, b, len(train_loader), time_per_batch, len(train_loader) * time_per_batch / 60))\n",
    "            print(mn)\n",
    "            print('-----------', flush=True)\n",
    "            start = time.time()\n",
    "    return pd.concat(tr, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(b, verbose=False):\n",
    "    \"\"\"\n",
    "    :param b: contains:\n",
    "          :param imgs: the image, [batch_size, 3, IM_SIZE, IM_SIZE]\n",
    "          :param all_anchors: [num_anchors, 4] the boxes of all anchors that we'll be using\n",
    "          :param all_anchor_inds: [num_anchors, 2] array of the indices into the concatenated\n",
    "                                  RPN feature vector that give us all_anchors,\n",
    "                                  each one (img_ind, fpn_idx)\n",
    "          :param im_sizes: a [batch_size, 4] numpy array of (h, w, scale, num_good_anchors) for each image.\n",
    "\n",
    "          :param num_anchors_per_img: int, number of anchors in total over the feature pyramid per img\n",
    "\n",
    "          Training parameters:\n",
    "          :param train_anchor_inds: a [num_train, 5] array of indices for the anchors that will\n",
    "                                    be used to compute the training loss (img_ind, fpn_idx)\n",
    "          :param gt_boxes: [num_gt, 4] GT boxes over the batch.\n",
    "          :param gt_classes: [num_gt, 2] gt boxes where each one is (img_id, class)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    result = detector[b]\n",
    "\n",
    "    losses = {}\n",
    "    losses['class_loss'] = detector.obj_loss(result)\n",
    "    losses['rel_loss'] = detector.rel_loss(result)\n",
    "    loss = sum(losses.values())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    clip_grad_norm(\n",
    "        [(n, p) for n, p in detector.named_parameters() if p.grad is not None],\n",
    "        max_norm=conf.clip, verbose=verbose, clip=True)\n",
    "    losses['total'] = loss\n",
    "    optimizer.step()\n",
    "    loss_pd = pd.Series({x: y.data[0] for x, y in losses.items()})\n",
    "    return result, loss_pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch():\n",
    "    detector.eval()\n",
    "    evaluator_list = [] # for calculating recall of each relationship except no relationship\n",
    "    evaluator_multiple_preds_list = []\n",
    "    for index, name in enumerate(ind_to_predicates):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        evaluator_list.append((index, name, BasicSceneGraphEvaluator.all_modes()))\n",
    "        evaluator_multiple_preds_list.append((index, name, BasicSceneGraphEvaluator.all_modes(multiple_preds=True)))\n",
    "    evaluator = BasicSceneGraphEvaluator.all_modes() # for calculating recall\n",
    "    evaluator_multiple_preds = BasicSceneGraphEvaluator.all_modes(multiple_preds=True)\n",
    "    for val_b, batch in enumerate(val_loader):\n",
    "        val_batch(conf.num_gpus * val_b, batch, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list)\n",
    "\n",
    "    recall = evaluator[conf.mode].print_stats()\n",
    "    recall_mp = evaluator_multiple_preds[conf.mode].print_stats()\n",
    "    \n",
    "    mean_recall = calculate_mR_from_evaluator_list(evaluator_list, conf.mode)\n",
    "    mean_recall_mp = calculate_mR_from_evaluator_list(evaluator_multiple_preds_list, conf.mode, multiple_preds=True)\n",
    "    \n",
    "    detector.train()\n",
    "    return recall, recall_mp, mean_recall, mean_recall_mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch(batch_num, b, evaluator, evaluator_multiple_preds, evaluator_list, evaluator_multiple_preds_list):\n",
    "    det_res = detector[b]\n",
    "    if conf.num_gpus == 1:\n",
    "        det_res = [det_res]\n",
    "\n",
    "    for i, (boxes_i, objs_i, obj_scores_i, rels_i, pred_scores_i) in enumerate(det_res):\n",
    "        gt_entry = {\n",
    "            'gt_classes': val.gt_classes[batch_num + i].copy(),\n",
    "            'gt_relations': val.relationships[batch_num + i].copy(),\n",
    "            'gt_boxes': val.gt_boxes[batch_num + i].copy(),\n",
    "        }\n",
    "        assert np.all(objs_i[rels_i[:, 0]] > 0) and np.all(objs_i[rels_i[:, 1]] > 0)\n",
    "\n",
    "        pred_entry = {\n",
    "            'pred_boxes': boxes_i * BOX_SCALE/IM_SCALE,\n",
    "            'pred_classes': objs_i,\n",
    "            'pred_rel_inds': rels_i,\n",
    "            'obj_scores': obj_scores_i,\n",
    "            'rel_scores': pred_scores_i,  # hack for now.\n",
    "        }\n",
    "\n",
    "        eval_entry(conf.mode, gt_entry, pred_entry, evaluator, evaluator_multiple_preds, \n",
    "                   evaluator_list, evaluator_multiple_preds_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.tb_log_dir is not None:\n",
    "    from tensorboardX import SummaryWriter\n",
    "    if not os.path.exists(conf.tb_log_dir):\n",
    "        os.makedirs(conf.tb_log_dir) \n",
    "    writer = SummaryWriter(log_dir=conf.tb_log_dir)\n",
    "    use_tb = True\n",
    "else:\n",
    "    use_tb = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optim(conf.lr * conf.num_gpus * conf.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts now!\n",
      "---Total norm 1.574 clip coef 3.176-----------------\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.584, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.505, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.500, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.459, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.407, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.380, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.363, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.353, (torch.Size([1024]))\n",
      "roi_fmap.1.3.weight                               : 0.347, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.313, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.313, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.278, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.240, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.239, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.225, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.205, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.205, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.185, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.180, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.175, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.159, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.145, (torch.Size([2048, 2048]))\n",
      "roi_fmap.1.0.weight                               : 0.138, (torch.Size([4096, 25088]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.077, (torch.Size([1024]))\n",
      "union_boxes.conv.4.weight                         : 0.074, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.073, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.065, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.062, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.049, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.044, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.042, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.040, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.039, (torch.Size([1024, 300]))\n",
      "roi_fmap_obj.3.weight                             : 0.039, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.038, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.038, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.028, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.023, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.023, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.023, (torch.Size([256, 512]))\n",
      "roi_fmap.1.3.bias                                 : 0.022, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.022, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.021, (torch.Size([256, 512]))\n",
      "union_boxes.conv.0.weight                         : 0.021, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.020, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.weight                             : 0.020, (torch.Size([4096, 25088]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.019, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.018, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.016, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.015, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.014, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.013, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.012, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.012, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.011, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.010, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.009, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.008, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.008, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.008, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.007, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.006, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.003, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.002, (torch.Size([768]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.002, (torch.Size([4096]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "union_boxes.conv.6.weight                         : 0.001, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.000, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 1b 1000/14430 0.478s/batch, 114.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.264373\n",
      "total         0.264373\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 2000/14430 0.478s/batch, 114.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.188185\n",
      "total         0.188185\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 3000/14430 0.481s/batch, 115.6m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.17735\n",
      "total         0.17735\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 4000/14430 0.481s/batch, 115.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.170706\n",
      "total         0.170706\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 5000/14430 0.484s/batch, 116.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.161689\n",
      "total         0.161689\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 6000/14430 0.484s/batch, 116.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.158433\n",
      "total         0.158433\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 7000/14430 0.481s/batch, 115.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.155099\n",
      "total         0.155099\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 8000/14430 0.487s/batch, 117.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.155351\n",
      "total         0.155351\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b 9000/14430 0.488s/batch, 117.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.153334\n",
      "total         0.153334\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.388 clip coef 12.891-----------------\n",
      "roi_fmap.1.0.weight                               : 0.223, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.132, (torch.Size([4096, 4096]))\n",
      "roi_fmap_obj.0.weight                             : 0.126, (torch.Size([4096, 25088]))\n",
      "roi_fmap.1.3.weight                               : 0.084, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.075, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.064, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.062, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.058, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.058, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.057, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.050, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.049, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.047, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.046, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.043, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.036, (torch.Size([512, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.035, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.034, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.033, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.032, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.031, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.030, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.026, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.025, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.025, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.024, (torch.Size([1024, 2048]))\n",
      "union_boxes.conv.0.weight                         : 0.023, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.021, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.018, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.016, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.016, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.014, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.011, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.009, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.009, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.008, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.008, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.007, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.004, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "union_boxes.conv.0.bias                           : 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.6.bias                           : 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "roi_fmap.1.3.bias                                 : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.6.weight                         : 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.001, (torch.Size([4096]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 1b10000/14430 0.485s/batch, 116.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.153151\n",
      "total         0.153151\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b11000/14430 0.491s/batch, 118.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.151143\n",
      "total         0.151143\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b12000/14430 0.504s/batch, 121.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.150797\n",
      "total         0.150797\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b13000/14430 0.485s/batch, 116.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.146995\n",
      "total         0.146995\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 1b14000/14430 0.517s/batch, 124.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.149267\n",
      "total         0.149267\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 1: (0.167)\n",
      "class_loss    0.00000\n",
      "rel_loss      0.16662\n",
      "total         0.16662\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.590830\n",
      "R@50: 0.642718\n",
      "R@100: 0.658206\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.675585\n",
      "R@50: 0.804487\n",
      "R@100: 0.874715\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.0890675027674102\n",
      "mR@50:  0.10932008129808121\n",
      "mR@100:  0.11668867556818033\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.1525395632622113\n",
      "mR@50:  0.27925417085969734\n",
      "mR@100:  0.384498990996055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alireza/home_at_filer2/tools/anaconda3/envs/kern/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/alireza/home_at_filer2/tools/anaconda3/envs/kern/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total norm 0.453 clip coef 11.045-----------------\n",
      "roi_fmap.1.0.weight                               : 0.262, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.203, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.168, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.085, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.074, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.066, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.061, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.060, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.053, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.052, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.049, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.049, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.045, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.042, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.040, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.038, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.038, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.038, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.037, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.036, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.033, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.033, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.030, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.030, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.029, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.026, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.024, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.024, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.023, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.021, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.019, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.017, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.017, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.015, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.013, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.013, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.010, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.008, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.008, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.005, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.004, (torch.Size([4096]))\n",
      "union_boxes.conv.6.bias                           : 0.004, (torch.Size([512]))\n",
      "union_boxes.conv.6.weight                         : 0.004, (torch.Size([512]))\n",
      "roi_fmap_obj.3.bias                               : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.002, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "roi_fmap_obj.0.bias                               : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 2b 1000/14430 0.485s/batch, 116.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.147531\n",
      "total         0.147531\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 2000/14430 0.486s/batch, 116.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.142847\n",
      "total         0.142847\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 3000/14430 0.484s/batch, 116.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.147192\n",
      "total         0.147192\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 4000/14430 0.487s/batch, 117.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.143578\n",
      "total         0.143578\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 5000/14430 0.482s/batch, 116.0m/epoch\n",
      "class_loss    0.0000\n",
      "rel_loss      0.1477\n",
      "total         0.1477\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 6000/14430 0.487s/batch, 117.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.142264\n",
      "total         0.142264\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 7000/14430 0.489s/batch, 117.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.144023\n",
      "total         0.144023\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 8000/14430 0.487s/batch, 117.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.143331\n",
      "total         0.143331\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b 9000/14430 0.481s/batch, 115.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.145548\n",
      "total         0.145548\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.479 clip coef 10.435-----------------\n",
      "roi_fmap.1.0.weight                               : 0.314, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.135, (torch.Size([4096, 4096]))\n",
      "roi_fmap_obj.0.weight                             : 0.124, (torch.Size([4096, 25088]))\n",
      "roi_fmap.1.3.weight                               : 0.114, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.093, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.086, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.080, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.078, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.073, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.070, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.059, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.059, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.057, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.049, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.048, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.047, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.047, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.047, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.044, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.043, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.043, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.041, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.041, (torch.Size([256, 512]))\n",
      "union_boxes.conv.4.weight                         : 0.039, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.039, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.033, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.029, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.027, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.027, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.026, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.024, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.024, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.022, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.021, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.021, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.018, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.016, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.015, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.013, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.012, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.011, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.011, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.009, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.005, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.005, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.004, (torch.Size([512]))\n",
      "roi_fmap.1.3.bias                                 : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "union_boxes.conv.6.weight                         : 0.003, (torch.Size([512]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.003, (torch.Size([3328]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 2b10000/14430 0.505s/batch, 121.4m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.14605\n",
      "total         0.14605\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b11000/14430 0.488s/batch, 117.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.144387\n",
      "total         0.144387\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b12000/14430 0.491s/batch, 118.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.143305\n",
      "total         0.143305\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b13000/14430 0.498s/batch, 119.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.142323\n",
      "total         0.142323\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 2b14000/14430 0.487s/batch, 117.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139733\n",
      "total         0.139733\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 2: (0.144)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.144288\n",
      "total         0.144288\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.616752\n",
      "R@50: 0.666058\n",
      "R@100: 0.679602\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.705123\n",
      "R@50: 0.827954\n",
      "R@100: 0.890543\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.13881520086411014\n",
      "mR@50:  0.1612917842764541\n",
      "mR@100:  0.17201480988284956\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.2080558786689167\n",
      "mR@50:  0.34019186467820667\n",
      "mR@100:  0.4600735975425894\n",
      "---Total norm 0.288 clip coef 17.338-----------------\n",
      "roi_fmap.1.0.weight                               : 0.157, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.089, (torch.Size([4096, 4096]))\n",
      "roi_fmap_obj.0.weight                             : 0.084, (torch.Size([4096, 25088]))\n",
      "roi_fmap.1.3.weight                               : 0.078, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.065, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.055, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.052, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.051, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.050, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.048, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.046, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.044, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.043, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.036, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.035, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.032, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.031, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.028, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.025, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.024, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.023, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.023, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.023, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.023, (torch.Size([1024]))\n",
      "union_boxes.conv.4.weight                         : 0.021, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.020, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.019, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.018, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.017, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.016, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.014, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.013, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.012, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.weight                         : 0.012, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.010, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.010, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.010, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.009, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.008, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.008, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.007, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.003, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.002, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.weight                         : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.bias                           : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.0.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 3b 1000/14430 0.481s/batch, 115.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.140483\n",
      "total         0.140483\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 2000/14430 0.521s/batch, 125.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.144327\n",
      "total         0.144327\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 3000/14430 0.488s/batch, 117.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139313\n",
      "total         0.139313\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 4000/14430 0.482s/batch, 116.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139942\n",
      "total         0.139942\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 5000/14430 0.484s/batch, 116.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137817\n",
      "total         0.137817\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 6000/14430 0.482s/batch, 116.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.143112\n",
      "total         0.143112\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 7000/14430 0.479s/batch, 115.2m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.13946\n",
      "total         0.13946\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 8000/14430 0.482s/batch, 116.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136506\n",
      "total         0.136506\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b 9000/14430 0.479s/batch, 115.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.140729\n",
      "total         0.140729\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.387 clip coef 12.905-----------------\n",
      "roi_fmap.1.0.weight                               : 0.217, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.121, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.115, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.090, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.088, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.3.weight                               : 0.086, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.078, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.063, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.062, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.058, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.049, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.048, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.045, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.045, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.044, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.042, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.042, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.038, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.037, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.035, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.035, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.033, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.033, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.028, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.027, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.024, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.023, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.022, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.021, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.021, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.020, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.019, (torch.Size([512, 1024]))\n",
      "union_boxes.conv.0.weight                         : 0.019, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.012, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.010, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.010, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.010, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.009, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.005, (torch.Size([768]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.6.bias                           : 0.003, (torch.Size([512]))\n",
      "union_boxes.conv.6.weight                         : 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.002, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 3b10000/14430 0.478s/batch, 114.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139634\n",
      "total         0.139634\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b11000/14430 0.497s/batch, 119.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136766\n",
      "total         0.136766\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b12000/14430 0.493s/batch, 118.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139073\n",
      "total         0.139073\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b13000/14430 0.491s/batch, 118.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.141281\n",
      "total         0.141281\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 3b14000/14430 0.488s/batch, 117.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137404\n",
      "total         0.137404\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 3: (0.140)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139774\n",
      "total         0.139774\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.603157\n",
      "R@50: 0.656114\n",
      "R@100: 0.671707\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.697568\n",
      "R@50: 0.828403\n",
      "R@100: 0.894167\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.13765396977881328\n",
      "mR@50:  0.170965769775074\n",
      "mR@100:  0.18328380314176246\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.22071568131748193\n",
      "mR@50:  0.38692649129567214\n",
      "mR@100:  0.5150823948370402\n",
      "---Total norm 0.348 clip coef 14.364-----------------\n",
      "roi_fmap.1.0.weight                               : 0.225, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.118, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.109, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.082, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.057, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.054, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.053, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.051, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.049, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.049, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.044, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.039, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.038, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.038, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.035, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.034, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.029, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.029, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.027, (torch.Size([1024]))\n",
      "union_boxes.conv.4.weight                         : 0.027, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.026, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.026, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.023, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.022, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.021, (torch.Size([1024, 300]))\n",
      "union_boxes.conv.0.weight                         : 0.021, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.018, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.018, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.016, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.014, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.013, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.011, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.008, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.008, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.007, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.006, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.006, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "union_boxes.conv.6.bias                           : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "roi_fmap.1.3.bias                                 : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.weight                         : 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.003, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "union_boxes.conv.0.bias                           : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 4b 1000/14430 0.482s/batch, 115.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136066\n",
      "total         0.136066\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 2000/14430 0.488s/batch, 117.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.138631\n",
      "total         0.138631\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 3000/14430 0.483s/batch, 116.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135555\n",
      "total         0.135555\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 4000/14430 0.480s/batch, 115.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136401\n",
      "total         0.136401\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 5000/14430 0.485s/batch, 116.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.132843\n",
      "total         0.132843\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 6000/14430 0.481s/batch, 115.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.133226\n",
      "total         0.133226\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 7000/14430 0.476s/batch, 114.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137568\n",
      "total         0.137568\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 8000/14430 0.482s/batch, 115.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135915\n",
      "total         0.135915\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b 9000/14430 0.497s/batch, 119.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136523\n",
      "total         0.136523\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.275 clip coef 18.194-----------------\n",
      "roi_fmap.1.0.weight                               : 0.178, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.082, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.080, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.061, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.050, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.048, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.041, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.040, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.039, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.031, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.030, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.029, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.028, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.027, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.026, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.026, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.025, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.025, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.024, (torch.Size([2048, 2048]))\n",
      "union_boxes.conv.4.weight                         : 0.024, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.023, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.023, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.022, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.020, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.017, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.017, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.017, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.016, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.014, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.013, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.012, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.010, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.010, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.010, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.007, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.007, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.006, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.005, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "roi_fmap.1.3.bias                                 : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.004, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.002, (torch.Size([4096]))\n",
      "union_boxes.conv.6.weight                         : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.002, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.002, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 4b10000/14430 0.495s/batch, 119.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.139814\n",
      "total         0.139814\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b11000/14430 0.480s/batch, 115.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.141748\n",
      "total         0.141748\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b12000/14430 0.478s/batch, 115.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.141031\n",
      "total         0.141031\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b13000/14430 0.484s/batch, 116.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137413\n",
      "total         0.137413\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 4b14000/14430 0.486s/batch, 116.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135922\n",
      "total         0.135922\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 4: (0.137)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137081\n",
      "total         0.137081\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.605383\n",
      "R@50: 0.655414\n",
      "R@100: 0.667810\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.708242\n",
      "R@50: 0.832621\n",
      "R@100: 0.899427\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.1722494373195552\n",
      "mR@50:  0.20258612320149905\n",
      "mR@100:  0.21218866199199798\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.25910772726704695\n",
      "mR@50:  0.4178087208865836\n",
      "mR@100:  0.5557279347523828\n",
      "---Total norm 0.437 clip coef 11.449-----------------\n",
      "roi_fmap.1.0.weight                               : 0.322, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.143, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.138, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.099, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.053, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.052, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.051, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.051, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.047, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.045, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.045, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.040, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.035, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.035, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.035, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.033, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.030, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.030, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.028, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.028, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.025, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.weight                         : 0.024, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.023, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.021, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.021, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.018, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.018, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.017, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.016, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.012, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.011, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.010, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.008, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.008, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.007, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.007, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "roi_fmap.1.3.bias                                 : 0.005, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.005, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.bias                           : 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.6.weight                         : 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 5b 1000/14430 0.489s/batch, 117.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.134405\n",
      "total         0.134405\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 2000/14430 0.486s/batch, 116.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135182\n",
      "total         0.135182\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 3000/14430 0.485s/batch, 116.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135987\n",
      "total         0.135987\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 4000/14430 0.495s/batch, 118.9m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.13292\n",
      "total         0.13292\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 5000/14430 0.488s/batch, 117.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136292\n",
      "total         0.136292\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 6000/14430 0.486s/batch, 117.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.136707\n",
      "total         0.136707\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 7000/14430 0.492s/batch, 118.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.133197\n",
      "total         0.133197\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 8000/14430 0.491s/batch, 118.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.134808\n",
      "total         0.134808\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b 9000/14430 0.500s/batch, 120.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.132061\n",
      "total         0.132061\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.269 clip coef 18.594-----------------\n",
      "roi_fmap.1.0.weight                               : 0.184, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.109, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.095, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.052, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.039, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.033, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.033, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.033, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.032, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.030, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.029, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.025, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.024, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.023, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.020, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.020, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.016, (torch.Size([768, 768]))\n",
      "union_boxes.conv.4.weight                         : 0.015, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.015, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.014, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.014, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.014, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.012, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.012, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.012, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.011, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.011, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.010, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.008, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.008, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.006, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.006, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.005, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.004, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.004, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.003, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.003, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.002, (torch.Size([1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.002, (torch.Size([256]))\n",
      "roi_fmap.1.3.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "union_boxes.conv.6.weight                         : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "union_boxes.conv.0.bias                           : 0.001, (torch.Size([256]))\n",
      "roi_fmap.1.0.bias                                 : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 5b10000/14430 0.506s/batch, 121.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135742\n",
      "total         0.135742\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b11000/14430 0.475s/batch, 114.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137216\n",
      "total         0.137216\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b12000/14430 0.477s/batch, 114.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.137266\n",
      "total         0.137266\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b13000/14430 0.479s/batch, 115.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135544\n",
      "total         0.135544\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 5b14000/14430 0.476s/batch, 114.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.134428\n",
      "total         0.134428\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 5: (0.135)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.135165\n",
      "total         0.135165\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.624121\n",
      "R@50: 0.673119\n",
      "R@100: 0.687101\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.719449\n",
      "R@50: 0.840382\n",
      "R@100: 0.904943\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.1299936922222661\n",
      "mR@50:  0.15471654384132993\n",
      "mR@100:  0.16236395727262543\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.22264494387933403\n",
      "mR@50:  0.38861463957359615\n",
      "mR@100:  0.5339326016256603\n"
     ]
    }
   ],
   "source": [
    "print(\"Training starts now!\")\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    rez = train_epoch(epoch)\n",
    "    print(\"overall{:2d}: ({:.3f})\\n{}\".format(epoch, rez.mean(1)['total'], rez.mean(1)), flush=True)\n",
    "\n",
    "    if use_tb:\n",
    "        writer.add_scalar('loss/rel_loss', rez.mean(1)['rel_loss'], epoch)\n",
    "        writer.add_scalar('loss/class_loss', rez.mean(1)['class_loss'], epoch)\n",
    "        writer.add_scalar('loss/total', rez.mean(1)['total'], epoch)\n",
    "\n",
    "    if conf.save_dir is not None:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': detector.state_dict(), #{k:v for k,v in detector.state_dict().items() if not k.startswith('detector.')},\n",
    "            # 'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "\n",
    "    recall, recall_mp, mean_recall, mean_recall_mp = val_epoch()\n",
    "    if use_tb:\n",
    "        for key, value in recall.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_with_constraint/' + key, value, epoch)\n",
    "        for key, value in recall_mp.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_without_constraint/' + key, value, epoch)\n",
    "        for key, value in mean_recall.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_with_constraint/mean ' + key, value, epoch)\n",
    "        for key, value in mean_recall_mp.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_without_constraint/mean ' + key, value, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] /= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts now!\n",
      "---Total norm 0.823 clip coef 6.072-----------------\n",
      "roi_fmap.1.0.weight                               : 0.572, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.271, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.255, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.183, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.133, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.114, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.111, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.099, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.098, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.097, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.094, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.083, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.078, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.075, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.073, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.072, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.072, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.071, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.066, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.065, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.063, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.062, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.059, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.059, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.056, (torch.Size([1024]))\n",
      "union_boxes.conv.4.weight                         : 0.055, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.053, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.048, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.048, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.046, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.043, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.042, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.039, (torch.Size([1024, 300]))\n",
      "union_boxes.conv.0.weight                         : 0.037, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.036, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.033, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.032, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.031, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.031, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.029, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.028, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.020, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.019, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.019, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.019, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.016, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.015, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.015, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.014, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.014, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.013, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.013, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.012, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.012, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.011, (torch.Size([256]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.010, (torch.Size([512]))\n",
      "union_boxes.conv.6.bias                           : 0.010, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.009, (torch.Size([256]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.008, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.007, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.007, (torch.Size([1024]))\n",
      "union_boxes.conv.6.weight                         : 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.002, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 6b 1000/14430 0.473s/batch, 113.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.131712\n",
      "total         0.131712\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 2000/14430 0.478s/batch, 114.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.132338\n",
      "total         0.132338\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 3000/14430 0.481s/batch, 115.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.131862\n",
      "total         0.131862\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 4000/14430 0.478s/batch, 115.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128128\n",
      "total         0.128128\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 5000/14430 0.476s/batch, 114.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.129143\n",
      "total         0.129143\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 6000/14430 0.479s/batch, 115.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128367\n",
      "total         0.128367\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 7000/14430 0.492s/batch, 118.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127835\n",
      "total         0.127835\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 8000/14430 0.481s/batch, 115.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.129099\n",
      "total         0.129099\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b 9000/14430 0.474s/batch, 113.9m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.13132\n",
      "total         0.13132\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 1.186 clip coef 4.217-----------------\n",
      "roi_fmap.1.0.weight                               : 0.794, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.495, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.445, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.253, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.188, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.164, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.145, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.128, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.121, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.117, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.115, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.107, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.105, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.096, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.094, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.085, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.085, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.081, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.071, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.069, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.064, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.062, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.060, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.057, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.056, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.055, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.055, (torch.Size([2048, 2048]))\n",
      "union_boxes.conv.0.weight                         : 0.052, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.048, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.047, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.047, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.045, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.039, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.035, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.034, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.033, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.033, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.031, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.029, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.028, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.023, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.022, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.022, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.021, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.019, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.019, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.019, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.017, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.015, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.015, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.012, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.011, (torch.Size([512]))\n",
      "union_boxes.conv.6.bias                           : 0.011, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.011, (torch.Size([256]))\n",
      "roi_fmap_obj.3.bias                               : 0.011, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.010, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.010, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.010, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.010, (torch.Size([512]))\n",
      "union_boxes.conv.6.weight                         : 0.009, (torch.Size([512]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.009, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.009, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.006, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.003, (torch.Size([3328]))\n",
      "union_boxes.conv.2.weight                         : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.002, (torch.Size([256]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 6b10000/14430 0.479s/batch, 115.1m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.12713\n",
      "total         0.12713\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b11000/14430 0.485s/batch, 116.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126251\n",
      "total         0.126251\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b12000/14430 0.477s/batch, 114.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125831\n",
      "total         0.125831\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b13000/14430 0.479s/batch, 115.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128853\n",
      "total         0.128853\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 6b14000/14430 0.475s/batch, 114.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126944\n",
      "total         0.126944\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 6: (0.129)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128889\n",
      "total         0.128889\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.629284\n",
      "R@50: 0.677606\n",
      "R@100: 0.692079\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.725648\n",
      "R@50: 0.846125\n",
      "R@100: 0.909695\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.15194852403665016\n",
      "mR@50:  0.18362476355607335\n",
      "mR@100:  0.19617421135939936\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.23623899574128773\n",
      "mR@50:  0.3962972653719072\n",
      "mR@100:  0.5434328923347035\n",
      "---Total norm 0.376 clip coef 13.299-----------------\n",
      "roi_fmap.1.0.weight                               : 0.287, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.112, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.095, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.088, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.055, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.052, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.045, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.042, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.040, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.037, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.037, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.034, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.033, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.032, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.031, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.028, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.026, (torch.Size([1024, 300]))\n",
      "union_boxes.conv.0.weight                         : 0.025, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.024, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.024, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.022, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.021, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.019, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.018, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.018, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.017, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.016, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.016, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.011, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.011, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.010, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.010, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.008, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.006, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "union_boxes.conv.6.bias                           : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.005, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.005, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.004, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.004, (torch.Size([768]))\n",
      "union_boxes.conv.6.weight                         : 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.004, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.002, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 7b 1000/14430 0.481s/batch, 115.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127799\n",
      "total         0.127799\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 2000/14430 0.478s/batch, 114.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126451\n",
      "total         0.126451\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 3000/14430 0.477s/batch, 114.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128235\n",
      "total         0.128235\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 4000/14430 0.473s/batch, 113.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128451\n",
      "total         0.128451\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 5000/14430 0.481s/batch, 115.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127398\n",
      "total         0.127398\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 6000/14430 0.496s/batch, 119.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.123843\n",
      "total         0.123843\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 7000/14430 0.482s/batch, 116.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127484\n",
      "total         0.127484\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 8000/14430 0.476s/batch, 114.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127446\n",
      "total         0.127446\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b 9000/14430 0.472s/batch, 113.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127403\n",
      "total         0.127403\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.821 clip coef 6.093-----------------\n",
      "roi_fmap.1.0.weight                               : 0.564, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.301, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.268, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.177, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.134, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.116, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.107, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.106, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.101, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.100, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.099, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.081, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.077, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.075, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.065, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.065, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.065, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.063, (torch.Size([512, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.059, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.058, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.054, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.047, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.047, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.045, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.045, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.045, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.044, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.044, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.044, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.042, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.041, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.038, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.036, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.032, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.032, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.029, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.028, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.027, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.023, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.021, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.019, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.018, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.017, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.016, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.015, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.014, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.013, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.012, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.010, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.010, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.010, (torch.Size([768]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.010, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.010, (torch.Size([4096]))\n",
      "union_boxes.conv.6.bias                           : 0.009, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "roi_fmap_obj.3.bias                               : 0.007, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.006, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.006, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.weight                         : 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "union_boxes.conv.0.bias                           : 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.004, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.002, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 7b10000/14430 0.477s/batch, 114.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126601\n",
      "total         0.126601\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b11000/14430 0.474s/batch, 113.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126362\n",
      "total         0.126362\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b12000/14430 0.477s/batch, 114.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128228\n",
      "total         0.128228\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b13000/14430 0.477s/batch, 114.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127656\n",
      "total         0.127656\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 7b14000/14430 0.474s/batch, 113.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127783\n",
      "total         0.127783\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 7: (0.127)\n",
      "class_loss    0.0000\n",
      "rel_loss      0.1273\n",
      "total         0.1273\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.628403\n",
      "R@50: 0.677127\n",
      "R@100: 0.691312\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.726104\n",
      "R@50: 0.846921\n",
      "R@100: 0.910970\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.15588773930026306\n",
      "mR@50:  0.1886213539686482\n",
      "mR@100:  0.19916953978968935\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.24361343380219047\n",
      "mR@50:  0.4099742983823715\n",
      "mR@100:  0.5507739428206073\n",
      "---Total norm 0.732 clip coef 6.831-----------------\n",
      "roi_fmap.1.0.weight                               : 0.524, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.297, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.251, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.142, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.101, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.085, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.081, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.077, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.073, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.068, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.065, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.062, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.058, (torch.Size([768, 768]))\n",
      "union_boxes.conv.4.weight                         : 0.058, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.058, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.056, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.052, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.047, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.046, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.042, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.039, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.039, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.038, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.036, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.weight                         : 0.032, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.031, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.029, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.026, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.024, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.021, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.020, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.020, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.017, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.016, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.015, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.014, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.012, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.012, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.012, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.010, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.010, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.008, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.008, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.008, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.008, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.007, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.007, (torch.Size([512]))\n",
      "roi_fmap_obj.3.bias                               : 0.007, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.006, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.006, (torch.Size([4096]))\n",
      "union_boxes.conv.6.weight                         : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "roi_fmap_obj.0.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 8b 1000/14430 0.481s/batch, 115.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125455\n",
      "total         0.125455\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 2000/14430 0.469s/batch, 112.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125914\n",
      "total         0.125914\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 3000/14430 0.457s/batch, 110.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.123929\n",
      "total         0.123929\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 4000/14430 0.466s/batch, 112.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.123691\n",
      "total         0.123691\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 5000/14430 0.456s/batch, 109.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.129196\n",
      "total         0.129196\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 6000/14430 0.455s/batch, 109.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127347\n",
      "total         0.127347\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 7000/14430 0.457s/batch, 109.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126809\n",
      "total         0.126809\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 8000/14430 0.453s/batch, 108.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128675\n",
      "total         0.128675\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b 9000/14430 0.455s/batch, 109.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.129141\n",
      "total         0.129141\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.497 clip coef 10.056-----------------\n",
      "roi_fmap.1.0.weight                               : 0.367, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.148, (torch.Size([4096, 4096]))\n",
      "roi_fmap_obj.0.weight                             : 0.137, (torch.Size([4096, 25088]))\n",
      "roi_fmap.1.3.weight                               : 0.112, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.077, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.075, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.074, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.066, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.064, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.062, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.055, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.052, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.048, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.041, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.041, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.038, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.037, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.033, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.032, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.030, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.029, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.029, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.028, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.026, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.025, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.024, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.023, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.022, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.020, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.020, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.019, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.019, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.018, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.012, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.011, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.010, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.010, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.009, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.008, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.007, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.007, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "roi_fmap.1.3.bias                                 : 0.006, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "union_boxes.conv.6.bias                           : 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.weight                         : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.004, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.004, (torch.Size([256]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.003, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 8b10000/14430 0.455s/batch, 109.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128293\n",
      "total         0.128293\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b11000/14430 0.455s/batch, 109.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126611\n",
      "total         0.126611\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b12000/14430 0.452s/batch, 108.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128387\n",
      "total         0.128387\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b13000/14430 0.453s/batch, 108.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126875\n",
      "total         0.126875\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 8b14000/14430 0.451s/batch, 108.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126113\n",
      "total         0.126113\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 8: (0.127)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126871\n",
      "total         0.126871\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.629482\n",
      "R@50: 0.677929\n",
      "R@100: 0.692223\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.727976\n",
      "R@50: 0.847510\n",
      "R@100: 0.910019\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.15280788531486952\n",
      "mR@50:  0.18620862545136546\n",
      "mR@100:  0.19421564617934148\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.2666997520264398\n",
      "mR@50:  0.4180061797770228\n",
      "mR@100:  0.5524386656020064\n",
      "---Total norm 0.505 clip coef 9.898-----------------\n",
      "roi_fmap.1.0.weight                               : 0.377, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.175, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.147, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.104, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.072, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.061, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.059, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.059, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.054, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.054, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.046, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.042, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.042, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.038, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.038, (torch.Size([1024, 300]))\n",
      "union_boxes.conv.4.weight                         : 0.038, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.035, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.034, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.033, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.029, (torch.Size([2048, 2048]))\n",
      "union_boxes.conv.0.weight                         : 0.029, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.028, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.026, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.025, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.024, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.022, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.021, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.021, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.020, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.020, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.019, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.017, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.016, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.013, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.011, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.011, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.011, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.009, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.009, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.008, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.006, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.bias                           : 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.006, (torch.Size([768]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.006, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.006, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "union_boxes.conv.6.weight                         : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "roi_fmap_obj.3.bias                               : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.003, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 9b 1000/14430 0.452s/batch, 108.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.122046\n",
      "total         0.122046\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 2000/14430 0.452s/batch, 108.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125953\n",
      "total         0.125953\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 3000/14430 0.457s/batch, 109.9m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.12462\n",
      "total         0.12462\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 4000/14430 0.450s/batch, 108.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125998\n",
      "total         0.125998\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 5000/14430 0.452s/batch, 108.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125872\n",
      "total         0.125872\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 6000/14430 0.455s/batch, 109.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125494\n",
      "total         0.125494\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 7000/14430 0.454s/batch, 109.3m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.124048\n",
      "total         0.124048\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 8000/14430 0.450s/batch, 108.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127821\n",
      "total         0.127821\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b 9000/14430 0.452s/batch, 108.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125287\n",
      "total         0.125287\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 1.194 clip coef 4.189-----------------\n",
      "roi_fmap.1.0.weight                               : 0.787, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.514, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.463, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.248, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.178, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.170, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.125, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.120, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.117, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.115, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.111, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.109, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.104, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.104, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.099, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.092, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.091, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.090, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.085, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.073, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.073, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.069, (torch.Size([256, 512]))\n",
      "union_boxes.conv.4.weight                         : 0.066, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.060, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.050, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.048, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.048, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.047, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.045, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.042, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.041, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.041, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.041, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.041, (torch.Size([1024]))\n",
      "union_boxes.conv.0.weight                         : 0.040, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.037, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.035, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.034, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.030, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.028, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.027, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.027, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.026, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.026, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.023, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.022, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.021, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.019, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.019, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.015, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.015, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.015, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.015, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.014, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.013, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.013, (torch.Size([256]))\n",
      "union_boxes.conv.6.bias                           : 0.013, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.013, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.012, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.012, (torch.Size([4096]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.011, (torch.Size([1024]))\n",
      "roi_fmap_obj.3.bias                               : 0.011, (torch.Size([4096]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.010, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.010, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.009, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.009, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.008, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.weight                         : 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.007, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.007, (torch.Size([1024]))\n",
      "union_boxes.conv.0.bias                           : 0.006, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.005, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.003, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.weight                         : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e 9b10000/14430 0.453s/batch, 109.1m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125968\n",
      "total         0.125968\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b11000/14430 0.455s/batch, 109.4m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125435\n",
      "total         0.125435\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b12000/14430 0.451s/batch, 108.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128829\n",
      "total         0.128829\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b13000/14430 0.455s/batch, 109.5m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.12739\n",
      "total         0.12739\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e 9b14000/14430 0.456s/batch, 109.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125872\n",
      "total         0.125872\n",
      "dtype: float64\n",
      "-----------\n",
      "overall 9: (0.126)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125847\n",
      "total         0.125847\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.629796\n",
      "R@50: 0.678356\n",
      "R@100: 0.692435\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.727292\n",
      "R@50: 0.846646\n",
      "R@100: 0.909028\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.152837804027647\n",
      "mR@50:  0.18826571817297807\n",
      "mR@100:  0.19994532683458907\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.24044062139402742\n",
      "mR@50:  0.40706678378704814\n",
      "mR@100:  0.5494975168230835\n",
      "---Total norm 0.500 clip coef 10.001-----------------\n",
      "roi_fmap.1.0.weight                               : 0.383, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.149, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.145, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.113, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.073, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.061, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.060, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.058, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.058, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.056, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.055, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.048, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.045, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.044, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.039, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.036, (torch.Size([512, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.036, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.032, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.031, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.028, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.027, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.027, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.023, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.weight                         : 0.022, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.020, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.019, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.018, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.018, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.018, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.018, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.017, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.016, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.015, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.014, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.011, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.010, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.010, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.009, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.008, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.007, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.007, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.007, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.007, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.007, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.007, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.006, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.005, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.005, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.005, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.6.bias                           : 0.005, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.005, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.004, (torch.Size([1024]))\n",
      "union_boxes.conv.6.weight                         : 0.004, (torch.Size([512]))\n",
      "roi_fmap_obj.3.bias                               : 0.004, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.003, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.003, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.003, (torch.Size([4096]))\n",
      "union_boxes.conv.0.bias                           : 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.001, (torch.Size([512]))\n",
      "union_boxes.conv.2.bias                           : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e10b 1000/14430 0.460s/batch, 110.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.126265\n",
      "total         0.126265\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 2000/14430 0.443s/batch, 106.5m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.124421\n",
      "total         0.124421\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 3000/14430 0.444s/batch, 106.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.124717\n",
      "total         0.124717\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 4000/14430 0.439s/batch, 105.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.124738\n",
      "total         0.124738\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 5000/14430 0.441s/batch, 106.0m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.122438\n",
      "total         0.122438\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 6000/14430 0.442s/batch, 106.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.123063\n",
      "total         0.123063\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 7000/14430 0.437s/batch, 105.2m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128425\n",
      "total         0.128425\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 8000/14430 0.443s/batch, 106.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.123119\n",
      "total         0.123119\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b 9000/14430 0.439s/batch, 105.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127413\n",
      "total         0.127413\n",
      "dtype: float64\n",
      "-----------\n",
      "---Total norm 0.306 clip coef 16.329-----------------\n",
      "roi_fmap.1.0.weight                               : 0.215, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.0.weight                             : 0.111, (torch.Size([4096, 25088]))\n",
      "roi_fmap_obj.3.weight                             : 0.109, (torch.Size([4096, 4096]))\n",
      "roi_fmap.1.3.weight                               : 0.062, (torch.Size([4096, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.weight: 0.049, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.weight: 0.040, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.weight: 0.039, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.obj_proj.weight                   : 0.038, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.weight     : 0.037, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.weight: 0.036, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.weight: 0.034, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.weight: 0.029, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.weight     : 0.028, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.weight                   : 0.027, (torch.Size([1024, 4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.weight: 0.024, (torch.Size([512, 1024]))\n",
      "union_boxes.conv.4.weight                         : 0.023, (torch.Size([512, 256, 3, 3]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.weight: 0.020, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.weight      : 0.019, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.weight     : 0.019, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.weight: 0.019, (torch.Size([768, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.weight      : 0.018, (torch.Size([1024, 300]))\n",
      "union_boxes.conv.0.weight                         : 0.016, (torch.Size([256, 2, 7, 7]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.0.linear.bias: 0.015, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.weight: 0.015, (torch.Size([1024, 768]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_pred.bias       : 0.014, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_pred.bias       : 0.014, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.0.linear.bias: 0.014, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.weight      : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.weight: 0.013, (torch.Size([2048, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.weight     : 0.013, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_pred.bias       : 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_pred.bias       : 0.013, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.weight       : 0.012, (torch.Size([1024, 300]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_img_pred.model.2.linear.bias: 0.012, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.weight: 0.011, (torch.Size([1024, 2048]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.weight: 0.010, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.weight: 0.010, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.2.linear.bias: 0.009, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.weight: 0.009, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.weight: 0.009, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_pred.model.0.linear.bias: 0.007, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.2.linear.bias: 0.006, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_pred.model.0.linear.bias: 0.005, (torch.Size([2048]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.weight     : 0.005, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.weight: 0.005, (torch.Size([3328, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.2.linear.bias: 0.004, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_ent.model.0.linear.bias: 0.004, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.weight: 0.004, (torch.Size([512, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.weight: 0.004, (torch.Size([256, 512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_img_ent.bias        : 0.004, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.weight      : 0.004, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.weight: 0.004, (torch.Size([1024, 3328]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.weight      : 0.003, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.rel_proj.bias                     : 0.003, (torch.Size([1024]))\n",
      "roi_fmap.1.3.bias                                 : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_pred.bias        : 0.003, (torch.Size([1024]))\n",
      "union_boxes.conv.6.bias                           : 0.003, (torch.Size([512]))\n",
      "roi_fmap_obj.3.bias                               : 0.003, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.0.linear.bias: 0.003, (torch.Size([768]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.2.linear.bias: 0.003, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_img_ent.model.2.linear.bias: 0.003, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.2.linear.bias: 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.weight      : 0.002, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.2.linear.bias: 0.002, (torch.Size([256]))\n",
      "union_boxes.conv.6.weight                         : 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.obj_proj.bias                     : 0.002, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_pred.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_img_pred.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_send_ont_ent.model.0.linear.bias: 0.002, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.weight     : 0.002, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.0.bias                           : 0.002, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_init_ont_ent.bias         : 0.002, (torch.Size([1024]))\n",
      "roi_fmap.1.0.bias                                 : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_w_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq5_u_ont_ent.bias        : 0.001, (torch.Size([1024]))\n",
      "union_boxes.conv.2.weight                         : 0.001, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "roi_fmap_obj.0.bias                               : 0.001, (torch.Size([4096]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.weight      : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.weight     : 0.001, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_pred.bias       : 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.0.linear.bias: 0.001, (torch.Size([3328]))\n",
      "ggnn_rel_reason.ggnn.fc_mp_receive_ont_ent.model.2.linear.bias: 0.001, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "union_boxes.conv.4.bias                           : 0.000, (torch.Size([512]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_pred.bias       : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_pred.weight     : 0.000, (torch.Size([1024, 1024]))\n",
      "union_boxes.conv.2.bias                           : 0.000, (torch.Size([256]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_img_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq3_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.weight      : 0.000, (torch.Size([1024, 1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_w_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_eq4_u_ont_ent.bias        : 0.000, (torch.Size([1024]))\n",
      "ggnn_rel_reason.ggnn.fc_output_proj_ont_pred.model.2.linear.bias: 0.000, (torch.Size([1024]))\n",
      "-------------------------------\n",
      "\n",
      "e10b10000/14430 0.440s/batch, 105.9m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125734\n",
      "total         0.125734\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b11000/14430 0.440s/batch, 105.8m/epoch\n",
      "class_loss    0.00000\n",
      "rel_loss      0.12753\n",
      "total         0.12753\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b12000/14430 0.439s/batch, 105.6m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.127645\n",
      "total         0.127645\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b13000/14430 0.440s/batch, 105.8m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.128723\n",
      "total         0.128723\n",
      "dtype: float64\n",
      "-----------\n",
      "\n",
      "e10b14000/14430 0.440s/batch, 105.7m/epoch\n",
      "class_loss    0.000000\n",
      "rel_loss      0.124651\n",
      "total         0.124651\n",
      "dtype: float64\n",
      "-----------\n",
      "overall10: (0.126)\n",
      "class_loss    0.000000\n",
      "rel_loss      0.125586\n",
      "total         0.125586\n",
      "dtype: float64\n",
      "======================predcls  recall with constraint============================\n",
      "R@20: 0.629782\n",
      "R@50: 0.678048\n",
      "R@100: 0.692594\n",
      "======================predcls  recall without constraint============================\n",
      "R@20: 0.727271\n",
      "R@50: 0.845666\n",
      "R@100: 0.908986\n",
      "\n",
      "\n",
      "======================predcls  mean recall with constraint============================\n",
      "mR@20:  0.1632150181668757\n",
      "mR@50:  0.19760370961491305\n",
      "mR@100:  0.2067982155702394\n",
      "\n",
      "\n",
      "======================predcls  mean recall without constraint============================\n",
      "mR@20:  0.24843208676915002\n",
      "mR@50:  0.41691214049341463\n",
      "mR@100:  0.5504711985438719\n"
     ]
    }
   ],
   "source": [
    "print(\"Training starts now!\")\n",
    "\n",
    "for epoch in range(6, 11):\n",
    "    rez = train_epoch(epoch)\n",
    "    print(\"overall{:2d}: ({:.3f})\\n{}\".format(epoch, rez.mean(1)['total'], rez.mean(1)), flush=True)\n",
    "\n",
    "    if use_tb:\n",
    "        writer.add_scalar('loss/rel_loss', rez.mean(1)['rel_loss'], epoch)\n",
    "        writer.add_scalar('loss/class_loss', rez.mean(1)['class_loss'], epoch)\n",
    "        writer.add_scalar('loss/total', rez.mean(1)['total'], epoch)\n",
    "\n",
    "    if conf.save_dir is not None:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': detector.state_dict(), #{k:v for k,v in detector.state_dict().items() if not k.startswith('detector.')},\n",
    "            # 'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(conf.save_dir, '{}-{}.tar'.format('vgrel', epoch)))\n",
    "\n",
    "    recall, recall_mp, mean_recall, mean_recall_mp = val_epoch()\n",
    "    if use_tb:\n",
    "        for key, value in recall.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_with_constraint/' + key, value, epoch)\n",
    "        for key, value in recall_mp.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_without_constraint/' + key, value, epoch)\n",
    "        for key, value in mean_recall.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_with_constraint/mean ' + key, value, epoch)\n",
    "        for key, value in mean_recall_mp.items():\n",
    "            writer.add_scalar('eval_' + conf.mode + '_without_constraint/mean ' + key, value, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KERN",
   "language": "python",
   "name": "kern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
